# Резюме о проделанной работе:

- инициализированы необходимые библиотеки, заданы условия визуализации и загрузили набор данных;
- настроили гиперпараметры: количество эпох, размер пакета, скорость обучения, коэффициент проверочной выборки и размер изображения;
- увеличили наши изображения несколькими способами, увеличив таким образом размер выборки;
- загрузили предварительно обученную модель EfficientNet B7, изменили «голову», добавили слой пакетной нормализации и оптимизатор скорости обучения Адама;
- настроили функции обратного вызова для сохранения промежуточного прогресса, остановки, если нет прогресса по метрике качества, и замедления скорости обучения, если нет прогресса по метрике потерь;
- обучили модель трижды - с замороженными весами, предварительно обученными в ImageNet, с половиной весов и со всеми весами;
- предсказали данные стандартным способом.

# По результатам можно сделать следующие выводы:

1. Увеличение количества эпох улучшает результат, если не доводить его до переобучения.
2. Уменьшение размера партии увеличивает время эксперимента, но помогает избежать ошибок ОЗУ.
3. Низкая скорость обучения замедляет эксперимент, но помогает избежать локальных минимумов.
4. Большой размер изображения замедляет эксперимент и перегружает оперативную память, но дает больше возможностей.
5. Увеличение изображения - хороший инструмент для увеличения размера выборки.
6. Пошаговое обучение улучшает результаты, но не было значительной разницы между полуобученной и полностью обученной сетью.
7. Очень важно следить за размером пакета, иначе обучение сети может быть прервано ошибкой ОЗУ.
8. Увеличение времени тестирования действительно улучшает результат прогнозирования.
​
